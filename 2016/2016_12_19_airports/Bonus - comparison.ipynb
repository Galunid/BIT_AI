{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "airports_raw = []\n",
    "filename = 'airports.dat'\n",
    "with open(filename, 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    try:\n",
    "        for row in reader:\n",
    "            airports_raw.append(row)\n",
    "    except csv.Error, e:\n",
    "        sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))\n",
    "\n",
    "airlines_raw = []\n",
    "filename = 'airlines.dat'\n",
    "with open(filename, 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    try:\n",
    "        for row in reader:\n",
    "            airlines_raw.append(row)\n",
    "    except csv.Error, e:\n",
    "        sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))\n",
    "\n",
    "routes_raw = []\n",
    "filename = 'routes.dat'\n",
    "with open(filename, 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    try:\n",
    "        for row in reader:\n",
    "            routes_raw.append(row)\n",
    "    except csv.Error, e:\n",
    "        sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))\n",
    "\n",
    "\n",
    "airports_df = pd.DataFrame(airports_raw)\n",
    "airlines_df = pd.DataFrame(airlines_raw)\n",
    "routes_df = pd.DataFrame(routes_raw)\n",
    "\n",
    "airports_df.columns = ['ID', 'Name', 'City', 'Country', 'IATA/FAA', 'ICAO','Latitude','Longitude','Altitude','Timezone','DST','Tz']\n",
    "airlines_df.columns = ['ID', 'Name','Alias','IATA','ICAO','Callsign','Country','Active']\n",
    "routes_df.columns = ['Airline', 'AirlineID', 'Source', 'Source ID', 'Destination', 'Destination ID', 'Codeshare', 'Stops', 'Equipment']\n",
    "\n",
    "airports_df['Longitude'] = pd.to_numeric(airports_df['Longitude']);\n",
    "airports_df['Latitude'] = pd.to_numeric(airports_df['Latitude']);\n",
    "\n",
    "geo_values = pd.concat([airports_df['Longitude'], airports_df['Latitude']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "geo_dataset = (np.array(geo_values), [random.choice([0,1]) for i in range(len(geo_values))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import cluster, datasets\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate datasets. We choose the size big enough to see the scalability\n",
    "# of the algorithms, but not too big to avoid too long running times\n",
    "n_samples = 1500\n",
    "noisy_circles = datasets.make_circles(n_samples=n_samples, factor=.5,\n",
    "                                      noise=.05)\n",
    "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=.05)\n",
    "blobs = datasets.make_blobs(n_samples=n_samples, random_state=8)\n",
    "no_structure = np.random.rand(n_samples, 2), None\n",
    "\n",
    "colors = np.array([x for x in 'bgrcmykbgrcmykbgrcmykbgrcmyk'])\n",
    "colors = np.hstack([colors] * 20)\n",
    "\n",
    "clustering_names = [\n",
    "    'MiniBatchKMeans', 'AffinityPropagation', 'MeanShift',\n",
    "    'SpectralClustering', 'Ward', 'AgglomerativeClustering',\n",
    "    'DBSCAN', 'Birch']\n",
    "\n",
    "plt.figure(figsize=(len(clustering_names) * 2 + 3, 9.5))\n",
    "plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05,\n",
    "                    hspace=.01)\n",
    "\n",
    "plot_num = 1\n",
    "\n",
    "datasets = [geo_dataset, noisy_circles]#[geo_dataset, noisy_circles, noisy_moons, blobs, no_structure]\n",
    "for i_dataset, dataset in enumerate(datasets):\n",
    "    X, y = dataset\n",
    "    # normalize dataset for easier parameter selection\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # estimate bandwidth for mean shift\n",
    "    bandwidth = cluster.estimate_bandwidth(X, quantile=0.3)\n",
    "\n",
    "    # connectivity matrix for structured Ward\n",
    "    connectivity = kneighbors_graph(X, n_neighbors=10, include_self=False)\n",
    "    # make connectivity symmetric\n",
    "    connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "\n",
    "    # create clustering estimators\n",
    "    ms = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    two_means = cluster.MiniBatchKMeans(n_clusters=2)\n",
    "    ward = cluster.AgglomerativeClustering(n_clusters=2, linkage='ward',\n",
    "                                           connectivity=connectivity)\n",
    "    spectral = cluster.SpectralClustering(n_clusters=2,\n",
    "                                          eigen_solver='arpack',\n",
    "                                          affinity=\"nearest_neighbors\")\n",
    "    dbscan = cluster.DBSCAN(eps=.2)\n",
    "    affinity_propagation = cluster.AffinityPropagation(damping=.9,\n",
    "                                                       preference=-200)\n",
    "\n",
    "    average_linkage = cluster.AgglomerativeClustering(\n",
    "        linkage=\"average\", affinity=\"cityblock\", n_clusters=2,\n",
    "        connectivity=connectivity)\n",
    "\n",
    "    birch = cluster.Birch(n_clusters=2)\n",
    "    clustering_algorithms = [\n",
    "        two_means, affinity_propagation, ms, spectral, ward, average_linkage,\n",
    "        dbscan, birch]\n",
    "    clustering_algorithms = [two_means, affinity_propagation, ms, spectral]\n",
    "    for name, algorithm in zip(clustering_names, clustering_algorithms):\n",
    "        # predict cluster memberships\n",
    "        print name\n",
    "        t0 = time.time()\n",
    "        algorithm.fit(X)\n",
    "        t1 = time.time()\n",
    "        if hasattr(algorithm, 'labels_'):\n",
    "            y_pred = algorithm.labels_.astype(np.int)\n",
    "        else:\n",
    "            y_pred = algorithm.predict(X)\n",
    "\n",
    "        # plot\n",
    "        plt.subplot(len(datasets), len(clustering_algorithms), plot_num)\n",
    "        if i_dataset == 0:\n",
    "            plt.title(name, size=18)\n",
    "        plt.scatter(X[:, 0], X[:, 1], color=colors[y_pred].tolist(), s=10)\n",
    "\n",
    "        if hasattr(algorithm, 'cluster_centers_'):\n",
    "            centers = algorithm.cluster_centers_\n",
    "            center_colors = colors[:len(centers)]\n",
    "            plt.scatter(centers[:, 0], centers[:, 1], s=100, c=center_colors)\n",
    "#         plt.xlim(-2, 2)\n",
    "#         plt.ylim(-2, 2)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plt.text(.99, .01, ('%.2fs' % (t1 - t0)).lstrip('0'),\n",
    "                 transform=plt.gca().transAxes, size=15,\n",
    "                 horizontalalignment='right')\n",
    "        plot_num += 1\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import cluster, datasets\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate datasets. We choose the size big enough to see the scalability\n",
    "# of the algorithms, but not too big to avoid too long running times\n",
    "n_samples = 1500\n",
    "noisy_circles = datasets.make_circles(n_samples=n_samples, factor=.5,\n",
    "                                      noise=.05)\n",
    "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=.05)\n",
    "blobs = datasets.make_blobs(n_samples=n_samples, random_state=8)\n",
    "no_structure = np.random.rand(n_samples, 2), None\n",
    "\n",
    "colors = np.array([x for x in 'bgrcmykbgrcmykbgrcmykbgrcmyk'])\n",
    "colors = np.hstack([colors] * 20)\n",
    "\n",
    "clustering_names = [\n",
    "    'MiniBatchKMeans', 'AffinityPropagation', 'MeanShift',\n",
    "    'SpectralClustering', 'Ward', 'AgglomerativeClustering',\n",
    "    'DBSCAN', 'Birch']\n",
    "\n",
    "plt.figure(figsize=(len(clustering_names) * 2 + 3, 9.5))\n",
    "plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05,\n",
    "                    hspace=.01)\n",
    "\n",
    "plot_num = 1\n",
    "\n",
    "datasets = [geo_dataset, noisy_circles]#[geo_dataset, noisy_circles, noisy_moons, blobs, no_structure]\n",
    "for i_dataset, dataset in enumerate(datasets):\n",
    "    X, y = dataset\n",
    "    # normalize dataset for easier parameter selection\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # estimate bandwidth for mean shift\n",
    "    bandwidth = cluster.estimate_bandwidth(X, quantile=0.3)\n",
    "\n",
    "    # connectivity matrix for structured Ward\n",
    "    connectivity = kneighbors_graph(X, n_neighbors=10, include_self=False)\n",
    "    # make connectivity symmetric\n",
    "    connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "\n",
    "    # create clustering estimators\n",
    "    ms = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    two_means = cluster.MiniBatchKMeans(n_clusters=2)\n",
    "    ward = cluster.AgglomerativeClustering(n_clusters=2, linkage='ward',\n",
    "                                           connectivity=connectivity)\n",
    "    spectral = cluster.SpectralClustering(n_clusters=2,\n",
    "                                          eigen_solver='arpack',\n",
    "                                          affinity=\"nearest_neighbors\")\n",
    "    dbscan = cluster.DBSCAN(eps=.2)\n",
    "    affinity_propagation = cluster.AffinityPropagation(damping=.9,\n",
    "                                                       preference=-200)\n",
    "\n",
    "    average_linkage = cluster.AgglomerativeClustering(\n",
    "        linkage=\"average\", affinity=\"cityblock\", n_clusters=2,\n",
    "        connectivity=connectivity)\n",
    "\n",
    "    birch = cluster.Birch(n_clusters=2)\n",
    "    clustering_algorithms = [\n",
    "        two_means, affinity_propagation, ms, spectral, ward, average_linkage,\n",
    "        dbscan, birch]\n",
    "    clustering_algorithms = [ward, average_linkage,\n",
    "        dbscan, birch]\n",
    "    for name, algorithm in zip(clustering_names, clustering_algorithms):\n",
    "        # predict cluster memberships\n",
    "        print name\n",
    "        t0 = time.time()\n",
    "        algorithm.fit(X)\n",
    "        t1 = time.time()\n",
    "        if hasattr(algorithm, 'labels_'):\n",
    "            y_pred = algorithm.labels_.astype(np.int)\n",
    "        else:\n",
    "            y_pred = algorithm.predict(X)\n",
    "\n",
    "        # plot\n",
    "        plt.subplot(len(datasets), len(clustering_algorithms), plot_num)\n",
    "        if i_dataset == 0:\n",
    "            plt.title(name, size=18)\n",
    "        plt.scatter(X[:, 0], X[:, 1], color=colors[y_pred].tolist(), s=10)\n",
    "\n",
    "        if hasattr(algorithm, 'cluster_centers_'):\n",
    "            centers = algorithm.cluster_centers_\n",
    "            center_colors = colors[:len(centers)]\n",
    "            plt.scatter(centers[:, 0], centers[:, 1], s=100, c=center_colors)\n",
    "#         plt.xlim(-2, 2)\n",
    "#         plt.ylim(-2, 2)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plt.text(.99, .01, ('%.2fs' % (t1 - t0)).lstrip('0'),\n",
    "                 transform=plt.gca().transAxes, size=15,\n",
    "                 horizontalalignment='right')\n",
    "        plot_num += 1\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
