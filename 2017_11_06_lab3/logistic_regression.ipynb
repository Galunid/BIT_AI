{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hi!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In today's workshop we are going to learn about most known concept of supervised learning which is `classification`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer Wisconsin (Diagnostic) Database\n",
      "=============================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      "References\n",
      "----------\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(load_breast_cancer().DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcin/.anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, train_size=0.7)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, train_size=0.66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What is classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is a problem of predicting discrete value (classes) for given features. It is mainly viewed as a supervised learning problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What about applying linear regression for classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.36900000e+01,   1.60700000e+01,   8.78400000e+01,\n",
       "         5.79100000e+02,   8.30200000e-02,   6.37400000e-02,\n",
       "         2.55600000e-02,   2.03100000e-02,   1.87200000e-01,\n",
       "         5.66900000e-02,   1.70500000e-01,   5.06600000e-01,\n",
       "         1.37200000e+00,   1.40000000e+01,   4.23000000e-03,\n",
       "         1.58700000e-02,   1.16900000e-02,   6.33500000e-03,\n",
       "         1.94300000e-02,   2.17700000e-03,   1.48400000e+01,\n",
       "         2.02100000e+01,   9.91600000e+01,   6.70600000e+02,\n",
       "         1.10500000e-01,   2.09600000e-01,   1.34600000e-01,\n",
       "         6.98700000e-02,   3.32300000e-01,   7.70100000e-02])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.45177198,  0.70504476,  0.25909605,  0.13313162,  0.50991642,\n",
       "        1.00308908,  0.85533749, -0.19038491,  1.31137713,  0.62773172,\n",
       "        0.18136785,  0.54662921,  1.1671905 ,  1.12018796,  0.79641662,\n",
       "       -0.23620468,  0.25932015,  0.22245168,  0.79455798,  1.02454931,\n",
       "       -0.00229577,  1.18048099,  1.18524382,  0.22118924,  0.83161913,\n",
       "        0.76266237,  0.3210468 , -0.29411628,  0.82571166,  1.0178464 ,\n",
       "        0.35594696,  0.92037322,  0.70263526,  1.05485984,  0.71479478,\n",
       "       -0.00457221,  0.22415378,  0.92790874,  0.65323519,  0.80416824,\n",
       "        0.99404035,  0.46243048,  0.85042148,  1.3789115 , -0.0497269 ,\n",
       "        0.06564306,  0.42152735,  0.75804468,  1.32428645,  1.15270242,\n",
       "        0.7975561 ,  1.06357537,  0.91700387,  0.81753486,  0.71633007,\n",
       "        0.59927682,  0.7071975 ,  0.83187121,  0.47839485,  0.9688968 ,\n",
       "        1.08972135,  0.61506731,  0.90444321,  0.49868239,  1.10871607,\n",
       "        0.68847029,  0.88163369,  0.77002993,  0.07319584,  1.04210579,\n",
       "        0.88780191, -0.23310258,  0.73119632,  0.32196629, -0.1280512 ,\n",
       "        0.78274128,  0.7336044 ,  1.01810428,  1.16635546, -0.11304097,\n",
       "        0.54944758,  0.69644593,  1.00330993,  0.8608346 ,  0.60331794,\n",
       "        0.07571022,  0.15405537,  0.24485888,  0.74228288,  0.57090085,\n",
       "        0.82952884, -0.19185383,  0.91851051,  0.91123655,  0.93750216,\n",
       "        0.92129703, -0.35391924,  0.64043287, -0.14490021,  1.02990832,\n",
       "        0.84454369,  0.55272366,  0.90733602,  0.67288023,  0.51127077,\n",
       "        0.92639759,  0.1230973 ,  0.61859207,  0.46460169, -0.21648339,\n",
       "        0.8471035 ,  0.77867613])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to interpret these predictions? Maybe we need something different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What is logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is about applying \"squashing\" function to the hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{y} = h_w(x)$$ \n",
    "\n",
    "$$h_w(x) = \\sum_{j=0}^k w_j x_j = wx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{y} = \\sigma(h_w(x))$$ \n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10)\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/+T1fEMnODgdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f062af93ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, sigmoid(x))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.inf), sigmoid(-np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about loss? Is MSE still applicable? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are reasons why we are not using MSE. Instead we use log-loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ L(w) = -\\sum_{i=0}^n y^{(i)}\\log{h_w(x^{(i)})} + (1-y^{(i)})\\log{(1-h_w(x^{(i)}))}$$\n",
    "\n",
    "$$ y^{(i)} \\in \\{0, 1\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f066867b0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y = 1\n",
    "\n",
    "x = np.linspace(0.0001, 1, 1000)\n",
    "plt.plot(x, -np.log(x))\n",
    "plt.ylim(-1, 10)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-596061e6f8b3>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-596061e6f8b3>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    plt.grid(True)b\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# y = 0\n",
    "\n",
    "x = np.linspace(0, 0.9999, 1000)\n",
    "plt.plot(x, -np.log(1 - x))\n",
    "plt.ylim(-1, 10)\n",
    "plt.grid(True)b\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about gradient descent procedure? How does it change? Let's derive gradient on blackboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = reload(solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias_feature(X):\n",
    "       return np.c_[np.ones(len(X)), X]\n",
    "X_train = add_bias_feature(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.zeros(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/E22AF74F2AF71F6B/Users/mprze/Dropbox/Studia/Bit/BIT_AI_old/2017_11_06_lab3/solutions.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10000):\n",
    "#     print(solutions.cost(W, X_train, y_train))\n",
    "    W = solutions.gradient_step(W, X_train, y_train, 0.0001)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/E22AF74F2AF71F6B/Users/mprze/Dropbox/Studia/Bit/BIT_AI_old/2017_11_06_lab3/solutions.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92713567839195976"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(solutions._hypotheses(W, X_train) >= 0.5, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression(C=10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98492462311557794"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_reg.fit(X_train, y_train)\n",
    "logistic_reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to deal with overfitting?\n",
    "\n",
    "**Regularization to the rescue!**\n",
    "\n",
    "In Logistic (as well as Linear) Regression we can make sure that elements of the weights vector don't grow too dramatically. We do this by penalizing their size additionally in the cost function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to measure performance of our model?\n",
    "#### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can divide classifications of our model into four classes:\n",
    "\n",
    "| Predicted/Actual | 0   | 1   |\n",
    "|------------------|-----|-----|\n",
    "| 0                | True negative | False negative|\n",
    "| 1                | False positive | True positive | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy - a first intuition**\n",
    "\n",
    "$$\n",
    "Accuracy = \\frac{T_p + T_n}{total}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-26-60d0e4f8ce8b>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-60d0e4f8ce8b>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    # results of classification for each example\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def accuracy(actual_predictions, model_predictions):\n",
    "    # implement me!\n",
    "    # both arguments are np.arrays of zeros and ones symbolizing \n",
    "    # results of classification for each exampleb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = solutions.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What problems do you see with such a metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out there is a more reliable way to measure the performance of our model:\n",
    "\n",
    "- **Precision** - *what fraction of our positive classifications is correct?*\n",
    "$$\n",
    "Precision = \\frac{T_p}{T_p + F_p}\n",
    "$$\n",
    "\n",
    "- **Recall** - *what fraction of actual positive examples has been classified correctly?*\n",
    "$$\n",
    "Recall = \\frac{T_p}{T_p + F_n}\n",
    "$$\n",
    "\n",
    "We want both of those values to be as high as possible (duh).\n",
    "However, sometimes we have to make a trade off between them and decide with our classification method that one will be higher and the other lower.\n",
    "\n",
    "###### Can you think of any simple ways to increase one of those metrics? (without changing the model or the data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the possible metrics which takes those two into account is the **F score**, which will be high if both precision and recall are high, but low if we sacrifice precision to increase recall or the other way around.\n",
    "\n",
    "$$\n",
    "F score = \\frac{2PR}{P + R}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(actual_predictions, model_predictions):\n",
    "    # implement me!\n",
    "    # both arguments are np.arrays of zeros and ones symbolizing \n",
    "    # results of classification for each example\n",
    "    \n",
    "def recall(actual_predictions, model_predictions):\n",
    "    # implement me!\n",
    "    # both arguments are np.arrays of zeros and ones symbolizing \n",
    "    # results of classification for each example\n",
    "    \n",
    "def f_score(actual_predictions, model_predictions):\n",
    "    # implement me!\n",
    "    # both arguments are np.arrays of zeros and ones symbolizing \n",
    "    # results of classification for each example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUROC Curve \n",
    "Another way to visualize the performance of our model is to plot \n",
    "\n",
    "**A**rea\n",
    "\n",
    "**U**nder\n",
    "\n",
    "**R**eceiver\n",
    "\n",
    "**O**perating\n",
    "\n",
    "**C**haracteristic\n",
    "\n",
    "curve.\n",
    "\n",
    "This curve indicates the relation between two metrics:\n",
    "\n",
    "- **True positive rate (TPR)** (which is another name for recall)\n",
    "\n",
    "*what fraction of actual positive examples has been classified correctly?*\n",
    "\n",
    "$$\n",
    "TPR = \\frac{T_p}{T_p + F_n} = Recall\n",
    "$$\n",
    "\n",
    "- **False positive rate (FPR)**\n",
    "\n",
    "\n",
    "*what fraction of actual negative examples has been classified incorrectly?*\n",
    "$$\n",
    "FPR = \\frac{F_p}{F_p + T_n}\n",
    "$$\n",
    "\n",
    "The metrics should be calculated for different thresholds of classification in the classifier and then plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr = recall\n",
    "\n",
    "def fpr(actual_predictions, model_predictions):\n",
    "    # implement me!\n",
    "    # both arguments are np.arrays of zeros and ones symbolizing \n",
    "    # results of classification for each example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = solutions.fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-d0a90ef2544c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassifications_for_thresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-d0a90ef2544c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassifications_for_thresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0,1, 0.02)\n",
    "\n",
    "classifications_for_thresholds = [model.classify(features, t) for t in thresholds]\n",
    "\n",
    "tprs = [tpr(actual_predictions, model_predictions) for model_predictions in classifications_for_thresholds]\n",
    "\n",
    "fprs = [fpr(actual_predictions, model_predictions) for model_predictions in classifications_for_thresholds]\n",
    "\n",
    "plt.plot(fprs, tprs)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
