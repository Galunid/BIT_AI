{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks - word model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.cuda.FloatTensor\n",
    "dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we'll play with a model that works with whole words. We'll try to learn and generate song by Bob Dylan!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!mkdir data/lyrics\n",
    "!wget -O data/lyrics.zip http://ujeb.se/fdGfO\n",
    "!yes |unzip data/lyrics.zip -d data/lyrics\n",
    "!ls data/lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_path = 'data/lyrics'\n",
    "files = [f for f in listdir(lyrics_path) if isfile(join(lyrics_path, f))]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def song_from_file(file, lyrics_path=lyrics_path):\n",
    "    with open(join(lyrics_path, file)) as f:\n",
    "        return f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to show the model more explicitly where songs start end, and where lines split, we'll introduce a couple of 'special' tokens:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_t = '<START>'\n",
    "end_t = '<END>'\n",
    "unk_t = '<UNK>'\n",
    "newline_t = '<NEWL>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function will split the lyrics into text tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def song_to_tokens(song_lines):\n",
    "    result = [start_t]\n",
    "    for line in song_lines:\n",
    "        line = re.sub(r'[^\\w\\s]','', line)\n",
    "        words = line.split()\n",
    "        words = [w.lower() for w in words]\n",
    "        result.extend(words)\n",
    "        result.append(newline_t)\n",
    "    result.append(end_t)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = song_from_file(files[0])\n",
    "song_to_tokens(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = [song_from_file(f) for f in files]\n",
    "songs_tokens = [song_to_tokens(s) for s in songs]\n",
    "all_tokens = []\n",
    "for t in songs_tokens:\n",
    "    all_tokens.extend(t)\n",
    "len(all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All songs consist of over 140k tokens. How many distinct tokens do we have, though?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tokens_all = sorted(list(set(all_tokens)))\n",
    "token_to_int_all = dict((t, i) for i, t in enumerate(sorted_tokens_all))\n",
    "int_to_token_all = dict((i, t) for i, t in enumerate(sorted_tokens_all))\n",
    "len(token_to_int_all), len(int_to_token_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whew! That's a lot! Let's try count the times each token appears in the lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_count_all = dict((t, 0) for t in sorted_tokens_all)\n",
    "for t in all_tokens:\n",
    "    token_count_all[t] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = list(token_count_all.values())\n",
    "x_min=0\n",
    "x_max=20\n",
    "plt.hist(counts, range=(x_min, x_max))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly half of the tokens have appeared just once throughout the whole Bob Dylan's creative process! As those tokens are quite rare, we'll drop them from our vocabulary - they will be represented by `<UNK>` token. This will make things much easier for the network, as it will have 5k fewer classes to choose from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_threshold = 1\n",
    "\n",
    "sorted_tokens = [unk_t] + [t for t in sorted_tokens_all if token_count_all[t] > vocab_threshold]\n",
    "\n",
    "token_to_int = dict((t, i) for i, t in enumerate(sorted_tokens))\n",
    "int_to_token = dict((i, t) for i, t in enumerate(sorted_tokens))\n",
    "\n",
    "print(sorted_tokens[0])\n",
    "(len(token_to_int),\n",
    "len(int_to_token), \n",
    "(start_t in sorted_tokens), \n",
    "(end_t in sorted_tokens), \n",
    "(unk_t in sorted_tokens), \n",
    "(newline_t in sorted_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_count = dict((t, 0) for t in sorted_tokens)\n",
    "for t in all_tokens:\n",
    "    try:\n",
    "        token_count[t] += 1\n",
    "    except:\n",
    "        token_count[unk_t] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = list(token_count.values())\n",
    "x_min = 0\n",
    "x_max = 20\n",
    "plt.hist(counts, range=(x_min, x_max))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for every OOV (out-of-vocabulary) word in the data, the `<UNK>` token will be assigned to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 30\n",
    "X_l = []\n",
    "Y_l = []\n",
    "\n",
    "for song in songs_tokens:\n",
    "    for i in range(len(song) - sequence_length):\n",
    "        sequence_in = song[i: i + sequence_length]\n",
    "        sequence_out = song[i + sequence_length]\n",
    "        X_l.append([token_to_int.get(token, token_to_int[unk_t]) for token in sequence_in])\n",
    "        Y_l.append(token_to_int.get(sequence_out, token_to_int[unk_t]))\n",
    "\n",
    "len(X_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like before, let's wrap the data into np.arrays and then PyTorch Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(X_l, (-1, sequence_length))\n",
    "Y = np.array(Y_l)\n",
    "data_size = X.shape[0]\n",
    "idx = np.arange(data_size)\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(idx)\n",
    "train_size = int(data_size * 0.9)\n",
    "# test_size = int(data_size * 0.03)\n",
    "\n",
    "train_idx = idx[:train_size]\n",
    "test_idx = idx[train_size:]\n",
    "\n",
    "X_train = X[train_idx]\n",
    "Y_train = Y[train_idx]\n",
    "\n",
    "X_test = X[test_idx]\n",
    "Y_test = Y[test_idx]\n",
    "\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_var = Variable(torch.Tensor(X_train).type(dtype)).long()\n",
    "Y_train_var = Variable(torch.Tensor(Y_train).type(dtype).long())\n",
    "\n",
    "X_test_var = Variable(torch.Tensor(X_test).type(dtype)).long()\n",
    "Y_test_var = Variable(torch.Tensor(Y_test).type(dtype).long())\n",
    "\n",
    "X_train_var.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the model. It will be very similiar to the previously used character model. The only major change is the word embedding layer at the top, which gradually learns vector representations of input tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WordNN(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim, vocab_size, targets_dim, lstm_layers_no=3):\n",
    "        super(WordNN, self).__init__()\n",
    "        self.lstm_layers_no = lstm_layers_no\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed_layer = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm_layer = nn.LSTM(embed_dim, hidden_dim, lstm_layers_no, dropout=0.3)\n",
    "        self.dropout_layer = nn.Dropout(0.3)\n",
    "        self.vec2token = nn.Linear(hidden_dim, targets_dim)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "    def init_hidden(self, batch_size=1):\n",
    "        self.hidden = (Variable(torch.zeros(self.lstm_layers_no, batch_size, self.hidden_dim).type(dtype)),\n",
    "                Variable(torch.zeros(self.lstm_layers_no, batch_size, self.hidden_dim).type(dtype)))\n",
    "    \n",
    "    def forward(self, sequence):\n",
    "        embeddings = self.embed_layer(sequence)\n",
    "        lstm_input = embeddings.permute(1, 0, 2)\n",
    "        lstm_out, self.hidden = self.lstm_layer(lstm_input, self.hidden)\n",
    "        \n",
    "        tags = self.vec2token(self.dropout_layer(self.hidden[0][self.lstm_layers_no-1]))\n",
    "        return tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 64\n",
    "hidden_dim = 1024\n",
    "\n",
    "model = WordNN(embed_dim, hidden_dim, len(token_to_int), len(int_to_token)).type(dtype)\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "batch_size = 32\n",
    "test_batch_size = 32\n",
    "epochs_no = 100\n",
    "\n",
    "loss_history = []\n",
    "for epoch in range(epochs_no):\n",
    "    model.train()\n",
    "    train_losses_l = []\n",
    "    for i in range(100):\n",
    "\n",
    "        model.zero_grad()\n",
    "        model.init_hidden(batch_size)\n",
    "        \n",
    "        idx = torch.Tensor(np.random.randint(X_train_var.size()[0], size=batch_size)).type(dtype).long()\n",
    "        sequence_in = X_train_var[idx]\n",
    "        \n",
    "        targets = Y_train_var[idx]\n",
    "        tag_scores = model(sequence_in)\n",
    "        loss = loss_fun(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses_l.append(loss.data.cpu().numpy()[0])\n",
    "        \n",
    "    model.eval()\n",
    "    model.init_hidden(test_batch_size)\n",
    "    \n",
    "    test_idx = torch.Tensor(np.random.randint(X_test_var.size()[0], size=test_batch_size)).type(dtype).long()\n",
    "    test_sequence_in = X_test_var[test_idx]\n",
    "    test_targets = Y_test_var[test_idx]\n",
    "    test_tag_scores = model(test_sequence_in)\n",
    "    test_loss = loss_fun(test_tag_scores, test_targets).data.cpu().numpy().sum()\n",
    "    train_losses = np.array(train_losses_l)\n",
    "\n",
    "    loss_history.append((train_losses.mean(), test_loss))\n",
    "\n",
    "    print(epoch, loss_history[-1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_from_model(seq_in):\n",
    "    seq_var = Variable(torch.Tensor(seq_in).type(dtype).long())\n",
    "    out = model(seq_var)\n",
    "    probs = nn.functional.softmax(out, dim=1).data.cpu().numpy()[0]\n",
    "    chosen = np.random.choice(np.arange(probs.shape[0]), p=probs)\n",
    "#     chosen = probs.argmax()\n",
    "    return int(chosen)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(start_seq):\n",
    "    model.init_hidden()\n",
    "    sys.stdout.write(' '.join(start_seq))\n",
    "    seq = [[token_to_int.get(t, unk_t) for t in start_seq]]\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        next_int = sample_from_model(seq)\n",
    "        next_token = int_to_token[next_int]\n",
    "        if next_token == '<END>':\n",
    "            done = True\n",
    "        if next_token == '<NEWL>':\n",
    "            next_token = '\\n'\n",
    "        sys.stdout.write(' ' + next_token)\n",
    "        seq = [seq[0][1:] + [next_int]]\n",
    "        if len(seq[0]) > sequence_length:\n",
    "            seq = seq[0, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_sequence = [ '<START>']\n",
    "model.eval()\n",
    "generate(start_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
