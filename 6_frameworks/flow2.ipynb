{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kB6QvPCxt3ut"
   },
   "source": [
    "# Tensorflow 2.0 \n",
    "\n",
    "Google Colaboratory link: \n",
    "https://colab.research.google.com/drive/1MTakxD_oF6gwwhrcNs03LA1eDjYiSSL5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9JtPWMgu_8qa"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu==2.0.0a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3oUllxf9t3uv"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ITnuG43ljQ4O"
   },
   "source": [
    "We'll now be exploring a brand-new tensorflow 2.0, which still in testing stage. \n",
    "\n",
    "Tensorflow 2.0 has gone through a lot of changes compared to 1.\\*, most notable of which is **eager execution** paradigm.\n",
    "\n",
    "\n",
    "Excitement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rJZtql6tt3uz"
   },
   "source": [
    "As in PyTorch, we'll start with the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mF7wKTOrt3u0"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X_train = iris['data']\n",
    "y_train = iris['target']\n",
    "# We'll train on the whole dataset - don't ever do that - but for ilustrating behaviour it's good enough!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QArfjf2Ot3u3"
   },
   "outputs": [],
   "source": [
    "# of course, you can also define your own operations - tensorflow's syntax is in many ways similar to numpy's \n",
    "def relu(activation):\n",
    "    return activation * tf.cast((activation > 0), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7qcqfNC2t3u6"
   },
   "outputs": [],
   "source": [
    "D_in, H, D_out = 4, 10, 3\n",
    "\n",
    "\n",
    "W1 = tf.Variable(tf.random.uniform((D_in, H)))\n",
    "W2 = tf.Variable(tf.random.uniform((H, D_out)))\n",
    "\n",
    "  \n",
    "def loss(y, y_pred):\n",
    "  labels = tf.one_hot(y, D_out)\n",
    "  return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=y_pred))\n",
    "\n",
    "def train_step(X, y, lr, W1, W2):\n",
    "  with tf.GradientTape() as t: \n",
    "    # gradient tape is needed by eager mode to keep track of what operations to calculate gradients of \n",
    "    y_pred = relu(X @ W1) @ W2\n",
    "    current_loss = loss(y, y_pred)\n",
    "  dW1, dW2 = t.gradient(current_loss, [W1, W2])\n",
    "  W1.assign_sub(lr * dW1)\n",
    "  W2.assign_sub(lr * dW2)\n",
    "  return current_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7WNpOHkUy363"
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "  current_loss = train_step(X_train, y_train, 0.1, W1, W2)\n",
    "  print(current_loss)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fflf-jh7-sVU"
   },
   "source": [
    "If this looks intuitive, it's because *it is*. \n",
    "\n",
    "In TF 1.0 eager execution was not the default way to go. Instead, you would have had to construct a *computation graph* of $W_1$ and $W_2$ and *placeholders* to which inputs to the computation graph would be put.\n",
    "\n",
    "This allowed for building of *static computation graphs*, which, after constructing could have been better-optimized by TF's insides, but not changed afterwards.\n",
    "\n",
    "**Benefits of static graphs**\n",
    "* define once, run many times\n",
    "* when the graph is defined, framework can optimize it\n",
    "* we know how everything is connected, so gradients are easy to compute\n",
    "* a once-defined graph can be optimized by TF's internals\n",
    "* more functional approach (if you like functional programming. It's awesome, really.)\n",
    "* graph can be serialized and run without the code that defined it\n",
    "\n",
    "**Flaws of static graphs**\n",
    "* code for defining the structure of the graph and for running computations through the graph is in different places, which may be confusing\n",
    "* once-defined graphs cannot be changed in any way\n",
    "* if-statements and for-loops are not supported and there are ugly workarounds to enable similiar stuff\n",
    "  * theoretically you could (and probably should) aim to replace them with mapping/reducing/filtering, but ML is a highly iterative process, so good luck with that :(\n",
    "  \n",
    "**Dynamic graphs**\n",
    "* constructed from scratch with each usage\n",
    "* you need the code that defined the graph\n",
    "* the execution of graph is much more like ordinary code (loops, conditional statements)\n",
    "  * useful e.g. in RNNs, where the output of the graph is input back into it\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HtVYWhfNt3vB"
   },
   "source": [
    "## As for CIFAR-10\n",
    "\n",
    "Let's now try to train a network on a more serious dataset!\n",
    "\n",
    "Thanks to all-new **Tensorflow Datasets API** we can download the dataset we want and build a processing pipeline for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CGoNrOjZt3vC"
   },
   "outputs": [],
   "source": [
    "ds_train, ds_test = tfds.load(name=\"cifar10\", split=[\"train\", \"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWE4AcfojlHC"
   },
   "outputs": [],
   "source": [
    "def pipeline(ds):\n",
    "  return ds.repeat().shuffle(1024).batch(128).map(lambda batch: (batch[\"image\"] / 255, batch[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sQQG6UPAg4JL"
   },
   "outputs": [],
   "source": [
    "cifar_train = pipeline(ds_train)\n",
    "cifar_test = pipeline(ds_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gPKhP73rt3vE"
   },
   "source": [
    "As opposed to PyTorch, TF 1.0 didn't povide one single way to minimize the amount of written code when creating the model.\n",
    "\n",
    "TF 2.0 changed that, with tf.keras (https://keras.io/) becoming the first-class citizen. The tf.Estimator API has also bben kept, mostly because guys at Google are too lazy to refactor all of their code :P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7iAJIjRGt3vc"
   },
   "source": [
    "Keras lets you define and train models much more simply. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xYyETCcccdb-"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CTWKqU-6XqTE"
   },
   "source": [
    "Firts, let's define our own layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-sR7JFLXwcK"
   },
   "outputs": [],
   "source": [
    "def conv_block(out_channels: int):\n",
    "  return k.models.Sequential([\n",
    "      k.layers.Conv2D(out_channels, 3, padding='same', activation='relu'),\n",
    "      k.layers.BatchNormalization(),\n",
    "      k.layers.Dropout(0.3)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qwsKz1E7t3vd"
   },
   "outputs": [],
   "source": [
    "model = k.models.Sequential([\n",
    "    k.layers.Conv2D(32, 3, activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
    "    conv_block(32),\n",
    "    conv_block(32),\n",
    "    k.layers.Conv2D(32, 3, padding='same', strides=2),\n",
    "    conv_block(64),\n",
    "    conv_block(64),\n",
    "    conv_block(64),\n",
    "    \n",
    "    k.layers.Conv2D(64, 3, padding='same', strides=2),\n",
    "    conv_block(128),\n",
    "    conv_block(128),\n",
    "    conv_block(128),\n",
    "    \n",
    "    k.layers.Conv2D(128, 3, padding='same', strides=2),\n",
    "    conv_block(256),\n",
    "    conv_block(256),\n",
    "\n",
    "    k.layers.Flatten(),\n",
    "\n",
    "    k.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer=k.optimizers.Adam(6e-4), \n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uLkCzVoqt3vf"
   },
   "source": [
    "Let's train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fFMq2RMKt3vg"
   },
   "outputs": [],
   "source": [
    "model.fit_generator(cifar_train, steps_per_epoch=400, epochs=10, validation_data=cifar_test, validation_steps=10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "flow2.0.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
