{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kB6QvPCxt3ut"
   },
   "source": [
    "# Tensorflow 1\n",
    "\n",
    "Google Colaboratory link: \n",
    "https://colab.research.google.com/drive/1giF0GHVgFTGEKCQho9iKd4p1osa80xGw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7BE9Oc_7ZfLM"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu==1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3oUllxf9t3uv"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BJJ75WhCt3uz"
   },
   "source": [
    "TensorFlow is a deep learning framework brought to you by Google. It allows you to build computational graphs from tensors and operations on them and then helps those _tensors flow_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rJZtql6tt3uz"
   },
   "source": [
    "As in PyTorch, we'll start with the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mF7wKTOrt3u0"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris[\"data\"], iris[\"target\"], test_size=0.2)\n",
    "iris[\"feature_names\"], iris[\"target_names\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-tzmxbNdt3u3"
   },
   "source": [
    "A computational graph is made of:\n",
    "* placeholders (inputs to the graph)\n",
    "* variables\n",
    "* operations on them and their results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QArfjf2Ot3u3"
   },
   "outputs": [],
   "source": [
    "# of course, you can also define your own operations - tensorflow's syntax is in many ways similar to numpy's \n",
    "def relu(activation):\n",
    "    return activation * tf.cast((activation > 0), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7qcqfNC2t3u6"
   },
   "outputs": [],
   "source": [
    "D_in, H, D_out = 4, 10, 3\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, D_in))\n",
    "y = tf.placeholder(tf.int32, shape=(None))\n",
    "\n",
    "L = tf.one_hot(y, D_out)\n",
    "W1 = tf.Variable(tf.random_uniform((D_in, H)))\n",
    "W2 = tf.Variable(tf.random_uniform((H, D_out)))\n",
    "\n",
    "# and our graph is buit here:\n",
    "y_pred = relu(X @ W1) @ W2 \n",
    "\n",
    "print(L.shape)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=L, logits=y_pred))\n",
    "\n",
    "\n",
    "# this is a more explicit, but also impractical AF method of performing gradient descent\n",
    "grad_W1, grad_W2 = tf.gradients(loss, [W1, W2])\n",
    "\n",
    "lr = 1e-2\n",
    "\n",
    "new_W1 = W1.assign(W1 - lr * grad_W1)\n",
    "new_W2 = W2.assign(W2 - lr * grad_W2)\n",
    "updates = tf.group(new_W1, new_W2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRngI4wdt3u7"
   },
   "source": [
    "In Tensorflow 1, as opposed to PyTorch graphs are constructed statically - which means you need to define them in your code and cannot change later.\n",
    "\n",
    "An interesting thing to note is that a graph can have many inputs and many outputs, such as `y_pred` and `loss` here\n",
    "\n",
    "Another important thing to know is that nothing has been calculated or initialized yet!\n",
    "\n",
    "In order to actually run the computations, we'll have to run them in tensorflow's `Session`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HtJEIO8kt3u8"
   },
   "outputs": [],
   "source": [
    "train_dict = {X: X_train, y: y_train}\n",
    "\n",
    "num_iterations = 500\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     with tf.device(\"/gpu:0\"): #\"/cpu:0\" or \"/gpu:0\"\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        loss_val, _ = sess.run([loss, updates], feed_dict=train_dict)\n",
    "        if i % 50 == 0: print(loss_val)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G9xB8TSKt3u-"
   },
   "source": [
    "Let's train again, but without perfoming Gradient Descent manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXgKIQLkt3u-"
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "train_dict = {X: X_train, y: y_train}\n",
    "\n",
    "num_iterations = 500\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/gpu:0\"): #\"/cpu:0\" or \"/gpu:0\"\n",
    "        tf.global_variables_initializer().run()\n",
    "        for i in range(num_iterations):\n",
    "            train_step.run(feed_dict=train_dict)\n",
    "            loss_val = loss.eval(feed_dict=train_dict)\n",
    "            if i % 50 == 0: print(loss_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HtVYWhfNt3vB"
   },
   "source": [
    "## We don't have to write everything manually, do we?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gPKhP73rt3vE"
   },
   "source": [
    "Tensorflow 1 provides implementations of typical  layers in it's `layers` module. However, as opposed to PyTorch, it doesn't have one single way to minimize the amount of written code when creating the model.\n",
    "\n",
    "Some of the high-level wrappers include:\n",
    "\n",
    "* `tf.layers`\n",
    "* `TFLearn`\n",
    "* `Estimator API`\n",
    "* `Pretty Tensor`\n",
    "* `Keras`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W_m10JMMt3vG"
   },
   "source": [
    "Of the above, `tf.Estimator` has for a long tme been the most preferred approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5szurX6t3vG"
   },
   "outputs": [],
   "source": [
    "def my_estimator(features, labels, mode):\n",
    "    \n",
    "    X = tf.cast(features, tf.float32)    \n",
    "    \n",
    "    hidden1 = tf.layers.dense(X, 10, activation=tf.nn.relu)\n",
    "    \n",
    "    hidden2 = tf.layers.dense(hidden1, 10, activation=tf.nn.relu)\n",
    "    \n",
    "    hidden3 = tf.layers.dense(hidden2, 3, activation=tf.nn.softmax)\n",
    "    \n",
    "    y_out = hidden2\n",
    "        \n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(input=y_out, axis=1),\n",
    "        \"probabilities\": y_out\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    labels_onehot = tf.one_hot(indices=labels, depth=10)\n",
    "    softmax_loss = tf.losses.softmax_cross_entropy(logits=y_out, onehot_labels=labels_onehot)\n",
    "  \n",
    "    loss = softmax_loss \n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        global_step = tf.train.get_global_step()\n",
    "        start_lr = 1e-2\n",
    "        lr = tf.train.exponential_decay(start_lr, global_step, 500, 0.9, staircase=True) # we can use tricks, such as a decaying learning rate\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "        train_op = optimizer.minimize(loss=loss, global_step=global_step)\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    eval_metric = {\n",
    "        \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KR_RrKl5t3vJ"
   },
   "source": [
    "In order for estimator to work, we must provide input functions for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SwTi-X75t3vJ"
   },
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=256,\n",
    "    num_epochs=None,\n",
    "    shuffle=True    \n",
    ")\n",
    "\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=X_test,\n",
    "    y=y_test,\n",
    "    num_epochs=1,\n",
    "    shuffle=False    \n",
    ")\n",
    "\n",
    "# this differs from test_input_fn in its number of epochs\n",
    "# if num_epochs == None, input_fn returns data for as long as we want it to (so it's good for training)\n",
    "train_test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=256,\n",
    "    num_epochs=1,\n",
    "    shuffle=True    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lKuxkvD2t3vM"
   },
   "outputs": [],
   "source": [
    "model = tf.estimator.Estimator(model_fn=my_estimator, model_dir='/tmp/my_cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOUbkLLjt3vT"
   },
   "outputs": [],
   "source": [
    "model.train(input_fn=train_input_fn, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpS7chDWt3vW"
   },
   "outputs": [],
   "source": [
    "test_results = model.evaluate(input_fn=test_input_fn)\n",
    "train_results = model.evaluate(input_fn=train_test_input_fn)\n",
    "print('train', train_results)\n",
    "print('test', test_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L0cnOASRpaBu"
   },
   "source": [
    "Over the last few years, Tensorflow has become the most popular go-to Deep Learning framework, especially for professionals who need their models production-ready. \n",
    "\n",
    "Apart from the basics we've covered here, it provides awesome tools such as Tensorboard and Tensorflow serving. Moreover, Tensorflow is also available in other programming laguages, not \n",
    "\n",
    "The one group who doesn't seem to have been won over are researchers:\n",
    "\n",
    "https://twitter.com/karpathy/status/868178954032513024\n",
    "\n",
    "Indeed, many people often complain about Tensorflow's non-intuitiveness. This is why Tensorflow 2.0 has been created, with `eager mode` as it's first-class citizen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KPYm-LyMrvHh"
   },
   "source": [
    "Let's now see what's changed in TF 2.0 !"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "flow1.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
