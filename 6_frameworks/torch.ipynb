{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zYu-wjTJvrWe"
   },
   "source": [
    "# PyTorch\n",
    "\n",
    "Google Colaboratory link: https://drive.google.com/file/d/1D89uzH6-9Qu7DPLJglqdHTgsr-7UX0E9/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wh-yIHJHvrWh"
   },
   "source": [
    "PyTorch is a spritual successor of Torch and is being implemented by Facebook. \n",
    "\n",
    "It operates on various levels of abstraction:\n",
    "\n",
    "* Tensor - something similar to `np.array` but can be stored on the GPU\n",
    "* Variable - a part of a computational graph. Holds tensors as the value of the variable, as well as variable's gradients.\n",
    "* Module - a neural network layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PockljsANm81"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as torch_datasets\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h1uRWWsgvrWi"
   },
   "source": [
    "We'll start by creating a simple, shallow model which we'll use to classify the Iris dataset ( https://archive.ics.uci.edu/ml/datasets/iris )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q5D74OdOvrWi"
   },
   "source": [
    "## First, let's load data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-SjHdXIUvrWj"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris['data']\n",
    "iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjdioe-uvrWl"
   },
   "outputs": [],
   "source": [
    "X = Variable(torch.FloatTensor(iris['data']), requires_grad=False)\n",
    "y = Variable(torch.LongTensor(iris['target']), requires_grad=False)\n",
    "# We'll train on the whole dataset - don't ever do that - but for ilustrating behaviour it's good enough!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OBmbXJonvrWo"
   },
   "source": [
    "This is an example of an autograd function - you can use them to define your own operations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oQs4rKJQvrWo"
   },
   "outputs": [],
   "source": [
    "# a helper function to measure accuracy\n",
    "def accuracy(logits, y):\n",
    "    return (logits == y).sum() / y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "suXRDkR1vrWq"
   },
   "outputs": [],
   "source": [
    "class MyReLU(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.clamp(min=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input < 0] = 0\n",
    "        return grad_input\n",
    "\n",
    "relu = MyReLU.apply\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SPu_G1f7vrWs"
   },
   "source": [
    "We can easily check whether GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DHnzGcuNvrWt"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ryWIeqrUvrWv"
   },
   "source": [
    "PyTorch works on dynamic computational graphs. It means that with every operation, the graph is constructed from scratch. It's slower than Tensorflow, but allows for nice things such as loops.\n",
    "\n",
    "The downside is that models don't infer dimensionality that easily. It can be a pain, especially when building more complex models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bww-_d7gvrWw"
   },
   "outputs": [],
   "source": [
    "D_in, H, D_out = 4, 10, 3\n",
    "\n",
    "X_t = X.to(device)\n",
    "y_t = y.to(device)\n",
    "w1 = torch.randn(D_in, H, requires_grad=True, device=device)\n",
    "w2 = torch.randn(H, D_out, requires_grad=True, device=device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "epochbar = tqdm(range(500))\n",
    "for t in epochbar:\n",
    "    \n",
    "    # Forward pass\n",
    "    y_pred = relu(X_t @ w1) @ w2\n",
    "    \n",
    "    loss = loss_fn(y_pred, y_t.long())\n",
    "\n",
    "    # Use autograd to compute the backward pass.\n",
    "    loss.backward()\n",
    "\n",
    "    # Backward pass\n",
    "    w1.data -= learning_rate * w1.grad.data\n",
    "    w2.data -= learning_rate * w2.grad.data\n",
    "\n",
    "    # Manually zero the gradients after updating weights\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()\n",
    "    \n",
    "    #\n",
    "    logits = torch.topk(y_pred, 1)[1].data.cpu().numpy().flatten()  \n",
    "    acc = accuracy(logits, y_t.data.cpu().numpy())\n",
    "    epochbar.set_description(\n",
    "            f\"epoch: {t} |\\t\" \n",
    "            f\"loss: {loss.item()} |\\t\"\n",
    "            f\"accuracy: {acc}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X0QD05tyvrWy"
   },
   "source": [
    "## Let's train a network on a more serious dataset - CIFAR-10 !\n",
    "\n",
    "CIFAR-10 is a very basic dataset, ideal for toying with image recognition. It contains small (32x32) images and 10 classes. There is also a more ambitious version od this dataset, called CIFAR-100.\n",
    "\n",
    "But first, we need to load the dataset and apply whatever preprocessing we want to, such as transforming images to tensors and normalizing the data. \n",
    "\n",
    "PyTorch has utilities for that as well. They can be found in https://pytorch.org/docs/stable/torchvision/index.html\n",
    "\n",
    "How cool is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fuPfpB_tQPXv"
   },
   "outputs": [],
   "source": [
    "image_transforms = T.Compose([\n",
    "    T.ToTensor(), # transforms PIL images to tensors (this includes transposing (H, W, C) -> (C, H, W))\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # image tensors now in range (0, 1)\n",
    "    T.Lambda(lambda t: t.to(device)) # moves the tensor to the appropriate device\n",
    "])\n",
    "\n",
    "label_transforms = T.Compose([\n",
    "    T.Lambda(lambda t: torch.tensor(t, device=device)) # moves the tensor to the appropriate device\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mma3JKU1PeMr"
   },
   "outputs": [],
   "source": [
    "cifar_train, cifar_test =  [\n",
    "    torch_datasets.CIFAR10(\n",
    "        root=\"/tmp\",\n",
    "        train=is_train, \n",
    "        download=True,\n",
    "        transform=image_transforms,\n",
    "        target_transform=label_transforms\n",
    "    )\n",
    "    for is_train in [True, False]\n",
    "]\n",
    "cifar_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hf-K9f3MRbXb"
   },
   "source": [
    "Is it a bird? Is it a plane?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uuYDcPouQwsJ"
   },
   "outputs": [],
   "source": [
    "cifar_names = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\"\n",
    "]\n",
    "img, label  = cifar_train[100]\n",
    "plt.imshow(img.permute(1,2,0).cpu())\n",
    "plt.title(f\"label {label}: {cifar_names[label]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QVcWleUNShEa"
   },
   "source": [
    "Finally, we'll wrap the dataset in a DataLoader, which will help us sample and iterate over it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3R7ayBe3S3I6"
   },
   "outputs": [],
   "source": [
    "loader_train = DataLoader(cifar_train, batch_size=128,shuffle=True)\n",
    "loader_test = DataLoader(cifar_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lcXGjUbfvrW8"
   },
   "source": [
    "In PyTorch you can not only use pre-implemented modules - you can also implement your own. \n",
    "\n",
    "The only thing to do is implement the forward pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YVksrDaovrW9"
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "      \n",
    "def conv_block(in_channels: int, out_channels: int):\n",
    "  return nn.Sequential(\n",
    "    nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "    nn.PReLU(),\n",
    "    nn.BatchNorm2d(out_channels),\n",
    "    nn.Dropout(p=0.3),\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-QV9scGAr3XW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XlImsKgvrXA"
   },
   "source": [
    "And this is an easy way to define a model:\n",
    "\n",
    "Note that you could also create non-sequential connections (like Inception layers) for example by implementing your own modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_JjBABKovrXB"
   },
   "outputs": [],
   "source": [
    "model_base = nn.Sequential( \n",
    "    conv_block(3, 32),\n",
    "    conv_block(32, 32),\n",
    "    conv_block(32, 32),\n",
    "\n",
    "    nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),\n",
    "    conv_block(32, 64),\n",
    "    conv_block(64, 64),\n",
    "    conv_block(64, 64),\n",
    "\n",
    "    nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "    conv_block(64, 128),\n",
    "    conv_block(128, 128),\n",
    "    conv_block(128, 128),\n",
    "\n",
    "    nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
    "    conv_block(128, 256),\n",
    "    conv_block(256, 256),\n",
    "    conv_block(256, 256),\n",
    "\n",
    "\n",
    "    Flatten(),\n",
    "    nn.Linear(4096, 10),  \n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sBbOQyMxvrXD"
   },
   "source": [
    "Before we train the model, let's see how fast it is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qL_3gJHvvrXD"
   },
   "outputs": [],
   "source": [
    "model_cpu = deepcopy(model_base)\n",
    "model_gpu = deepcopy(model_base).to(device)\n",
    "x_cpu = torch.randn(64, 3, 32, 32)\n",
    "x_gpu = torch.randn(64, 3, 32, 32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0P6DefC-vrXI"
   },
   "outputs": [],
   "source": [
    "%timeit ans = model_cpu(x_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tt1PPzlAvrXJ"
   },
   "outputs": [],
   "source": [
    "torch.cuda.synchronize() # Make sure there are no pending GPU computations\n",
    "%timeit ans = model_gpu(x_gpu)        # Feed it through the model! \n",
    "torch.cuda.synchronize() # Make sure there are no pending GPU computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NMN11tzyvrXN"
   },
   "source": [
    "Now let's have fun with the model and train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U_3hoUCXvrXO"
   },
   "outputs": [],
   "source": [
    "torch.cuda.random.manual_seed(2137)\n",
    "torch.random.manual_seed(2137)\n",
    "\n",
    "model = deepcopy(model_base).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=6e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DpOhw6cGvrXS"
   },
   "source": [
    "How accurate is our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGxgQcHDvrXQ"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    # training\n",
    "    model.train()\n",
    "    epochbar = tqdm(loader_train)\n",
    "    accuracies = []\n",
    "    losses =[]\n",
    "    for X, y in epochbar:\n",
    "        y_pred = model(X)\n",
    "        _, logits = torch.max(y_pred, 1)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        accuracy = (logits == y).sum().item() / y.nelement()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        accuracies.append(accuracy)\n",
    "        losses.append(loss.item())\n",
    "    print(\n",
    "          f\"iter: {i} | \" \n",
    "          f\"train_loss: {np.mean(losses)} | \"\n",
    "          f\"train_acc: {np.mean(accuracies)} | \"\n",
    "      )\n",
    "    \n",
    "    # testing\n",
    "    model.eval() # mode where gradients are not computed\n",
    "    epochbar = tqdm(loader_test)\n",
    "    accuracies = []\n",
    "    losses =[]\n",
    "    for X, y in epochbar:\n",
    "        y_pred = model(X)\n",
    "        _, logits = torch.max(y_pred, 1)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        accuracy = (logits == y).sum().item() / y.nelement()\n",
    "        accuracies.append(accuracy)\n",
    "        losses.append(loss.item())\n",
    "    print(\n",
    "          f\"iter: {i} | \" \n",
    "          f\"test_loss: {np.mean(losses)} | \"\n",
    "          f\"test_acc: {np.mean(accuracies)} | \"\n",
    "      )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "torch.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
