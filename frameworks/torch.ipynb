{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact, fixed\n",
    "import ipywidgets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch operates on various levels of abstraction:\n",
    "\n",
    "* Tensor - something similar to `np.array` but can be stored on the GPU\n",
    "* Variable - a part of a computational graph. Holds tensors as the value of the variable, as well as variable's gradients.\n",
    "* Module - a neural network layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's load data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris['data']\n",
    "iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = Variable(torch.FloatTensor(iris['data']), requires_grad=False)\n",
    "y = Variable(torch.LongTensor(iris['target']), requires_grad=False)\n",
    "# We'll train on the whole dataset - don't ever do that - but for ilustrating behaviour it's good enough!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of an autograd function - you can use them to define your own operations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a helper function to measure accuracy\n",
    "def accuracy(logits, y):\n",
    "    return (logits == y).sum() / y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyReLU(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.clamp(min=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input < 0] = 0\n",
    "        return grad_input\n",
    "\n",
    "relu = MyReLU.apply\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch works on dynamic computational graphs. It means that with every operation, the graph is constructed from scratch. It's slower, but allows for nice things such as loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "\n",
    "D_in, H, D_out = 4, 10, 3\n",
    "\n",
    "X_t = X.type(dtype)\n",
    "y_t = y.type(dtype)\n",
    "w1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=True)\n",
    "w2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=True)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "for t in range(500):\n",
    "    \n",
    "    # Forward pass\n",
    "    y_pred = relu(X_t @ w1) @ w2\n",
    "\n",
    "    # Compute and print loss\n",
    "    \n",
    "    loss = loss_fn(y_pred, y_t.long())\n",
    "\n",
    "    # Use autograd to compute the backward pass.\n",
    "    loss.backward()\n",
    "\n",
    "    # Backward pass\n",
    "    w1.data -= learning_rate * w1.grad.data\n",
    "    w2.data -= learning_rate * w2.grad.data\n",
    "\n",
    "    # Manually zero the gradients after updating weights\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()\n",
    "    \n",
    "    #\n",
    "    logits = torch.topk(y_pred, 1)[1].data.cpu().numpy().flatten()  \n",
    "    acc = accuracy(logits, y_t.data.cpu().numpy())\n",
    "    if t % 50 == 0: print(t, loss.data[0], acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train a network on a more serious dataset - CIFAR-10 !\n",
    "\n",
    "But first, let's load (already normalized!) data. PyTorch has utilities for that as well. How cool is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkSampler(sampler.Sampler):\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "NUM_TRAIN = 49000\n",
    "NUM_VAL = 1000\n",
    "\n",
    "cifar10_train = dset.CIFAR10('.', train=True, download=True,\n",
    "                           transform=T.ToTensor())\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, sampler=ChunkSampler(NUM_TRAIN, 0))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('.', train=True, download=True,\n",
    "                           transform=T.ToTensor())\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('.', train=False, download=True,\n",
    "                          transform=T.ToTensor())\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's inside the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar = list(loader_train)[0][0].numpy()\n",
    "cifar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cifar(i):\n",
    "    print(i)\n",
    "    x = cifar[i].transpose(1, 2, 0)\n",
    "    plt.imshow(x)\n",
    "    plt.show()\n",
    "\n",
    "interact(show_cifar, i=ipywidgets.IntSlider(min=0, max=63))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset(m):\n",
    "    if hasattr(m, 'reset_parameters'):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch you can not only use pre-implemented modules - you can also implement your own. The only thing to do is implement the forward pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is an easy way to define a model:\n",
    "\n",
    "Note that you could also create non-sequential connections (like Inception layers) for example by implementing your own modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_base = nn.Sequential( \n",
    "    nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "    nn.PReLU(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "    nn.PReLU(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),\n",
    "    nn.PReLU(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.Dropout(p=0.3),\n",
    "    \n",
    "    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "    nn.PReLU(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "    nn.PReLU(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "    nn.PReLU(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.Dropout(p=0.3),\n",
    "    \n",
    "    nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "    nn.PReLU(),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "    nn.PReLU(),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
    "    nn.PReLU(),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.Dropout(p=0.3),\n",
    "    Flatten(),\n",
    "    nn.Linear(2048, 10),  \n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train the model, let's see how fast it is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "gpu_dtype = dtype = torch.cuda.FloatTensor\n",
    "cpu_dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy \n",
    "model_cpu = model_base.type(cpu_dtype)\n",
    "model_gpu = copy.deepcopy(model_base).type(gpu_dtype)\n",
    "x = torch.randn(64, 3, 32, 32).type(cpu_dtype)\n",
    "x_var = Variable(x.type(cpu_dtype)) \n",
    "x_gpu = torch.randn(64, 3, 32, 32).type(gpu_dtype)\n",
    "x_var_gpu = Variable(x.type(gpu_dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%timeit \n",
    "ans = model_cpu(x_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%timeit \n",
    "torch.cuda.synchronize() # Make sure there are no pending GPU computations\n",
    "ans = model_gpu(x_var_gpu)        # Feed it through the model! \n",
    "torch.cuda.synchronize() # Make sure there are no pending GPU computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have fun with the model and train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.random.manual_seed(2137)\n",
    "\n",
    "dtype = gpu_dtype\n",
    "\n",
    "model = model_base.type(dtype)\n",
    "model.apply(reset)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    print('EPOCH', i)\n",
    "    for e, (x, y) in enumerate(loader_train):\n",
    "        model.train()\n",
    "        x_var = Variable(x.type(gpu_dtype))\n",
    "        y_var = Variable(y.type(gpu_dtype).long())\n",
    "        y_pred = model(x_var)\n",
    "        logits = torch.topk(y_pred, 1)[1].data.cpu().numpy().flatten()    \n",
    "        loss = loss_fn(y_pred, y_var.long())\n",
    "        if (e % 100) == 0: print(e, loss.data[0], accuracy(logits, y_var.data.cpu().numpy()))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How accurate is our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for loader in [loader_train, loader_val, loader_test]:\n",
    "    acc = 0\n",
    "    div = 0\n",
    "    for (x,y) in loader:\n",
    "        model.eval()\n",
    "        x_var = Variable(x.type(gpu_dtype), volatile=True)\n",
    "        y_var = Variable(y.type(gpu_dtype).long())\n",
    "        y_pred = model(x_var)\n",
    "        logits = torch.topk(y_pred, 1)[1].data.cpu().numpy().flatten()\n",
    "        acc += accuracy(logits, y_var.data.cpu().numpy())\n",
    "        div += 1\n",
    "\n",
    "    print('accuracy:', acc / div)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
