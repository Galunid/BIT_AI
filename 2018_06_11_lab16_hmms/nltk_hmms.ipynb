{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMMs in Natural Language Processing\n",
    "\n",
    "In this example we'll see how HMMs perform in one of the task they're most widely used for - part-of-speech tagging. For that purpose, we'll utilize the NLTK library, which provides a variety of tools for the purpose of NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "from nltk.tag import hmm\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.data.path.append('/home/marcin/.nltk_data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the NLTK datasets are huge, you have to download them first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can move on to our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "data = list(treebank.tagged_sents()[:4000])\n",
    "random.shuffle(data)\n",
    "train_data = data[:3000]\n",
    "test_data = data[3000:]\n",
    "\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those tags in capitals don't tell a lot! Let's inspect them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = set()\n",
    "\n",
    "for sentence in train_data:\n",
    "    for word, tag in sentence:\n",
    "        all_tags.add(tag)\n",
    "\n",
    "all_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully, NLTK can also tell us what they mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in all_tags:\n",
    "    print(tag)\n",
    "    nltk.help.upenn_tagset(tag)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand the dataset, let's train a HMM on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = hmm.HiddenMarkovModelTrainer()\n",
    "tagger = trainer.train_supervised(train_data)\n",
    "tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger._states\n",
    "# tagger._symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tagger.tag(\"Joe met Joanne in Delhi .\".split()))\n",
    "\n",
    "print(tagger.tag(\"Chicago is the birthplace of Ginny\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the tagger do on the training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger.test(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger.test(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, this sucks.\n",
    "\n",
    "Let's play with the data a bit to see if we can improve those results. We'll stem the words to make the datasets more uniform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "porter.stem('intelligence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_stemmed(data):\n",
    "    return [ [(porter.stem(word), tag) for word, tag in sent] for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_train_data = to_stemmed(train_data)\n",
    "stemmed_test_data = to_stemmed(test_data)\n",
    "\n",
    "train_data[0], stemmed_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_tagger = trainer.train_supervised(stemmed_train_data)\n",
    "stemmed_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_tagger.test(stemmed_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_tagger.test(stemmed_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can train other classifiers on the data. \n",
    "\n",
    "Firts, some utilities to transform data into numerical fearures. We won't try too hard - the datapoint will consist of the word in question, as well as the previous word - so the same data HMM would take into account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def token_to_features(sentence, index, neighbors=3):\n",
    "    result = {\n",
    "        'word': sentence[index],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1]\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def untag(tagged_sentence):\n",
    "    return [w for w, t in tagged_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_X_y(tagged_sentences):\n",
    "    X, y = [], []\n",
    "    for tagged in tagged_sentences:\n",
    "        untagged = untag(tagged)\n",
    "        for index in range(len(tagged)):\n",
    "            X.append(token_to_features(untagged, index))\n",
    "            y.append(tagged[index][1])\n",
    " \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data[:10000]\n",
    "# dataset = to_stemmed(data)\n",
    "\n",
    "X_dict, y = to_X_y(dataset)\n",
    "\n",
    "vectorizer = DictVectorizer()\n",
    "X = vectorizer.fit_transform(X_dict)\n",
    "\n",
    "split = int(len(y) * 0.7)\n",
    "X_train = X[:split]\n",
    "X_test = X[split:]\n",
    "y_train = y[:split]\n",
    "y_test = y[split:]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use three very simple classifiers - they won't have any recurrent properties. The only recurrence happens in the datapoints, which contain the $n^{th}$ and $n-1^{th}$ word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "linear_model = LogisticRegression()\n",
    "neural_network = MLPClassifier(verbose=True, max_iter=10)\n",
    "\n",
    "decision_tree, linear_model, neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for classifier in [decision_tree, linear_model, neural_network]:\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred_train = classifier.predict(X_train)\n",
    "    y_pred_test = classifier.predict(X_test)\n",
    "    print('train', accuracy_score(y_train, y_pred_train))\n",
    "    print('test', accuracy_score(y_test, y_pred_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voila. Looks like there's a good reason why HMMs aren't as hot a topic anymore :P"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
