{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/hmmlearn/hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hidden states (temeperature)\n",
    "hidden_states = {'cold': 0,\n",
    "                 'hot': 1\n",
    "                }\n",
    "# observable states (numbers of eaten cones)\n",
    "observable_states = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood - the forward algorithm\n",
    "\n",
    "In this case, we're working with a pre trained HMM - which means all the essential parameters must be set manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hmm.MultinomialHMM(n_components = len(hidden_states), verbose=True)\n",
    "\n",
    "# initial probability vector of length n_hidden_states\n",
    "model.startprob_ = np.array([0.5, 0.5])\n",
    "\n",
    "# transition matrix - likelihood of transitioning between hidden states\n",
    "# shape = n_hidden_states x n_hidden_states\n",
    "model.transmat_ = np.array([\n",
    "  [0.7, 0.3],\n",
    "  [0.4, 0.6]\n",
    "])\n",
    "\n",
    "# emission matrix - likelihood of particular observation given each hidden state\n",
    "# shape = n_hidden_states x n_observable_states\n",
    "model.emissionprob_ = np.array([\n",
    "  [0.7, 0.3, 0.0],\n",
    "  [0.0, 0.4, 0.6]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = np.atleast_2d([0, 2, 2]).T\n",
    "np.e ** model.score(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most likely sequence - Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprob, states = model.decode(observations)\n",
    "[list(hidden_states.keys())[s] for s in states]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a HMM - forward-backward algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categorical_distribution(center, distr_range, n_categories):\n",
    "    assert(center in range(n_categories))\n",
    "    assert(distr_range < n_categories)\n",
    "    broad_result = np.zeros(2*n_categories)\n",
    "    distr_range += 1\n",
    "    for i in range(distr_range):\n",
    "        broad_result[n_categories + i] = broad_result[n_categories - i] = distr_range - i\n",
    "        \n",
    "    left = n_categories - center\n",
    "    right = 2*n_categories - center\n",
    "    result = broad_result[left:right]\n",
    "    return result / result.sum() # normalization, so that sum =1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to generate data, let's generate probabilities of transistions between observable states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_trans_probs = np.array(\n",
    "    [categorical_distribution(i, 2, len(observable_states)) for i in observable_states]\n",
    ")\n",
    "\n",
    "obs_initial_probs = np.ones(len(observable_states)) / len(observable_states)\n",
    "print('initial')\n",
    "print(obs_initial_probs)\n",
    "print('transitions')\n",
    "print(obs_trans_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(length, init_probs=obs_initial_probs, trans_probs=obs_trans_probs, n_categories=len(observable_states)):\n",
    "    result = []\n",
    "    result.append(np.random.choice(n_categories, p=init_probs))\n",
    "    for i in range(length -1):\n",
    "        result.append(np.random.choice(n_categories, p=obs_trans_probs[result[i]]))\n",
    "    \n",
    "    presence = [i in result for i in range(n_categories)]\n",
    "    return result if all(presence) else generate_sequence(length, init_probs, trans_probs, n_categories)\n",
    "\n",
    "generate_sequence(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = np.array([generate_sequence(10) for _ in range(100)])\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hmm.MultinomialHMM(n_components=len(hidden_states))\n",
    "\n",
    "model = model.fit(data_train) #, lengths=[len(d) for d in data_train])\n",
    "\n",
    "print('startprob')\n",
    "print(model.startprob_)\n",
    "print('transmat')\n",
    "print(model.transmat_)\n",
    "print('emissions')\n",
    "print(model.emissionprob_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z2 = remodel.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
