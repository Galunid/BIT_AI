{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "\n",
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.utils import to_categorical\n",
    "from cleverhans.utils import set_log_level\n",
    "from cleverhans.utils_tf import model_train, model_eval, batch_eval\n",
    "from cleverhans.attacks import FastGradientMethod, SaliencyMapMethod\n",
    "from cleverhans.attacks_tf import jacobian_graph, jacobian_augmentation\n",
    "\n",
    "from cleverhans_tutorials.tutorial_models import make_basic_cnn, MLP\n",
    "from cleverhans_tutorials.tutorial_models import Flatten, Linear, ReLU, Softmax\n",
    "\n",
    "from ipywidgets import interact, fixed\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??make_basic_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_attacked_model(sess, x, y, X_train, Y_train, X_test, Y_test,\n",
    "              nb_epochs, batch_size, learning_rate,\n",
    "              rng):\n",
    "    # Define TF model graph (for the black-box model)\n",
    "    model = make_basic_cnn()\n",
    "    predictions = model(x)\n",
    "    print(\"Defined TensorFlow model graph.\")\n",
    "\n",
    "    # Train an MNIST model\n",
    "    train_params = {\n",
    "        'nb_epochs': nb_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate\n",
    "    }\n",
    "    model_train(sess, x, y, predictions, X_train, Y_train, verbose=False,\n",
    "                args=train_params, rng=rng)\n",
    "\n",
    "    # Print out the accuracy on legitimate data\n",
    "    eval_params = {'batch_size': batch_size}\n",
    "    accuracy = model_eval(sess, x, y, predictions, X_test, Y_test,\n",
    "                          args=eval_params)\n",
    "    print('Test accuracy of black-box on legitimate test '\n",
    "          'examples: ' + str(accuracy))\n",
    "\n",
    "    return model, predictions, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_log_level(logging.DEBUG)\n",
    "accuracies = {}\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_start=0\n",
    "train_end=60000\n",
    "test_start=0\n",
    "test_end=10000\n",
    "nb_classes=10\n",
    "batch_size=128\n",
    "learning_rate=0.001\n",
    "nb_epochs=10\n",
    "holdout=150\n",
    "data_aug=6\n",
    "nb_epochs_s=10\n",
    "lmbda=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/t10k-labels-idx1-ubyte.gz\n",
      "X_train shape: (60000, 28, 28, 1)\n",
      "X_test shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = data_mnist(train_start=train_start,\n",
    "                                              train_end=train_end,\n",
    "                                              test_start=test_start,\n",
    "                                              test_end=test_end)\n",
    "\n",
    "# Initialize substitute training set reserved for adversary\n",
    "X_sub = X_test[:holdout]\n",
    "Y_sub = np.argmax(Y_test[:holdout], axis=1)\n",
    "\n",
    "# Redefine test set as remaining samples unavailable to adversaries\n",
    "X_test = X_test[holdout:]\n",
    "Y_test = Y_test[holdout:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label smoothing\n",
    "label_smooth = .1\n",
    "Y_train = Y_train.clip(label_smooth / 9., 1. - label_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined TensorFlow model graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/unj/adversarial_examples/src/cleverhans/cleverhans/utils_tf.py:112: UserWarning: verbose argument is deprecated and will be removed on 2018-02-11. Instead, use utils.set_log_level(). For backward compatibility, log_level was set to logging.WARNING (30).\n",
      "  warnings.warn(\"verbose argument is deprecated and will be removed\"\n"
     ]
    }
   ],
   "source": [
    "# Define input and output TF placeholders\n",
    "x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "# Seed random number generator so tutorial is reproducible\n",
    "rng = np.random.RandomState([2017, 12, 13])\n",
    "\n",
    "\n",
    "prep_attacked = prep_attacked_model(sess, x, y, X_train, Y_train, X_test, Y_test,\n",
    "                          nb_epochs, batch_size, learning_rate,\n",
    "                          rng=rng)\n",
    "model, bbox_preds, accuracies['attacked'] = prep_attacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fgsm = FastGradientMethod(model, sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fgsm_params = {'eps': 0.3,\n",
    "               'clip_min': 0.,\n",
    "               'clip_max': 1.}\n",
    "adv_x_fgsm = fgsm.generate(x, **fgsm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_x_fgsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pretty_print_list(l):\n",
    "    pprint({idx: f'{x:.2f}' for idx, x in enumerate(l)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(idx, adv_x):\n",
    "    adv = adv_x.eval({x: X_test[idx:idx+1]}, sess)\n",
    "    results = model(x).eval({x: X_test[idx:idx+1]},session=sess)\n",
    "    adv_results = model(x).eval({x: adv},session=sess)\n",
    "\n",
    "    plt.imshow(X_test[idx, ..., 0], cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(adv[0, ..., 0], cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Targeted:\", results.argmax(), \"Adversarial:\", adv_results.argmax())\n",
    "    print(\"Targeted probabilities\")\n",
    "    pretty_print_list(results.reshape(-1).tolist())\n",
    "    print(\"Adversarial probabilities\")\n",
    "    pretty_print_list(adv_results.reshape(-1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot, idx=(0, len(X_test) - 1), adv_x=fixed(adv_x_fgsm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_y_target(x=None):\n",
    "    if x is None:\n",
    "        return None\n",
    "    else:\n",
    "        one_hot_target = np.zeros((1, nb_classes), dtype=np.float32)\n",
    "        one_hot_target[0, x] = 1\n",
    "        return one_hot_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jsma_params = {\n",
    "    'theta': 1.,\n",
    "    'gamma': 0.1,\n",
    "    'clip_min': 0.,\n",
    "    'clip_max': 1.,\n",
    "    'y_target': get_y_target(5)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jsma = SaliencyMapMethod(model, sess=sess)\n",
    "adv_x_jsma = jsma.generate(x, **jsma_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot, idx=(0, len(X_test) - 1), adv_x=fixed(adv_x_jsma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLACK-BOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def substitute_model(img_rows=28, img_cols=28, nb_classes=10):\n",
    "    \"\"\"\n",
    "    Defines the model architecture to be used by the substitute. Use\n",
    "    the example model interface.\n",
    "    :param img_rows: number of rows in input\n",
    "    :param img_cols: number of columns in input\n",
    "    :param nb_classes: number of classes in output\n",
    "    :return: tensorflow model\n",
    "    \"\"\"\n",
    "    input_shape = (None, img_rows, img_cols, 1)\n",
    "\n",
    "    # Define a fully connected model (it's different than the black-box)\n",
    "    layers = [Flatten(),\n",
    "              Linear(200),\n",
    "              ReLU(),\n",
    "              Linear(200),\n",
    "              ReLU(),\n",
    "              Linear(nb_classes),\n",
    "              Softmax()]\n",
    "\n",
    "    return MLP(layers, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_sub(sess, x, y, bbox_preds, X_sub, Y_sub, nb_classes,\n",
    "              nb_epochs_s, batch_size, learning_rate, data_aug, lmbda,\n",
    "              rng):\n",
    "    \"\"\"\n",
    "    This function creates the substitute by alternatively\n",
    "    augmenting the training data and training the substitute.\n",
    "    :param sess: TF session\n",
    "    :param x: input TF placeholder\n",
    "    :param y: output TF placeholder\n",
    "    :param bbox_preds: output of black-box model predictions\n",
    "    :param X_sub: initial substitute training data\n",
    "    :param Y_sub: initial substitute training labels\n",
    "    :param nb_classes: number of output classes\n",
    "    :param nb_epochs_s: number of epochs to train substitute model\n",
    "    :param batch_size: size of training batches\n",
    "    :param learning_rate: learning rate for training\n",
    "    :param data_aug: number of times substitute training data is augmented\n",
    "    :param lmbda: lambda from arxiv.org/abs/1602.02697\n",
    "    :param rng: numpy.random.RandomState instance\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Define TF model graph (for the black-box model)\n",
    "    model_sub = substitute_model()\n",
    "    preds_sub = model_sub(x)\n",
    "    print(\"Defined TensorFlow model graph for the substitute.\")\n",
    "\n",
    "    # Define the Jacobian symbolically using TensorFlow\n",
    "    grads = jacobian_graph(preds_sub, x, nb_classes)\n",
    "\n",
    "    # Train the substitute and augment dataset alternatively\n",
    "    for rho in range(data_aug):\n",
    "        print(\"Substitute training epoch #\" + str(rho))\n",
    "        train_params = {\n",
    "            'nb_epochs': nb_epochs_s,\n",
    "            'batch_size': batch_size,\n",
    "            'learning_rate': learning_rate\n",
    "        }\n",
    "        model_train(sess, x, y, preds_sub, X_sub, to_categorical(Y_sub),\n",
    "                    init_all=False, verbose=False, args=train_params,\n",
    "                    rng=rng)\n",
    "\n",
    "        # If we are not at last substitute training iteration, augment dataset\n",
    "        if rho < data_aug - 1:\n",
    "            print(\"Augmenting substitute training data.\")\n",
    "            # Perform the Jacobian augmentation\n",
    "            X_sub = jacobian_augmentation(sess, x, X_sub, Y_sub, grads, lmbda)\n",
    "\n",
    "            print(\"Labeling substitute training data.\")\n",
    "            # Label the newly generated synthetic points using the black-box\n",
    "            Y_sub = np.hstack([Y_sub, Y_sub])\n",
    "            X_sub_prev = X_sub[int(len(X_sub)/2):]\n",
    "            eval_params = {'batch_size': batch_size}\n",
    "            bbox_val = batch_eval(sess, [x], [bbox_preds], [X_sub_prev],\n",
    "                                  args=eval_params)[0]\n",
    "            # Note here that we take the argmax because the adversary\n",
    "            # only has access to the label (not the probabilities) output\n",
    "            # by the black-box model\n",
    "            Y_sub[int(len(X_sub)/2):] = np.argmax(bbox_val, axis=1)\n",
    "\n",
    "    return model_sub, preds_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sub_out = train_sub(sess, x, y, bbox_preds, X_sub, Y_sub,\n",
    "                          nb_classes, nb_epochs_s, batch_size,\n",
    "                          learning_rate, data_aug, lmbda, rng=rng)\n",
    "model_sub, preds_sub = train_sub_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fgsm_bb = FastGradientMethod(model_sub, sess=sess)\n",
    "fgsm_params_bb = {'eps': 0.6,\n",
    "               'clip_min': 0.,\n",
    "               'clip_max': 1.}\n",
    "adv_x_fgsm_bb = fgsm_bb.generate(x, **fgsm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot, idx=(0, len(X_test) - 1), adv_x=fixed(adv_x_fgsm_bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jsma_bb = SaliencyMapMethod(model_sub, sess=sess)\n",
    "jsma_params_bb = {\n",
    "    'theta': 1.,\n",
    "    'gamma': 0.1,\n",
    "    'clip_min': 0.,\n",
    "    'clip_max': 1.,\n",
    "    'y_target': get_y_target(0)\n",
    "}\n",
    "\n",
    "adv_x_jsma_bb = jsma_bb.generate(x, **jsma_params_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot, idx=(0, len(X_test) - 1), adv_x=fixed(adv_x_jsma_bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:adversarial]",
   "language": "python",
   "name": "conda-env-adversarial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
